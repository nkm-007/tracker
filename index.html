<!DOCTYPE html>
<html>
<head>
    <title>Smart Face Tracker</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script src="https://unpkg.com/peerjs@1.5.2/dist/peerjs.min.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: sans-serif; }
        #videoContainer { position: absolute; width: 100%; height: 100%; }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }
        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        
        /* HUD Controls */
        #hud {
            position: fixed; bottom: 20px; left: 50%; transform: translateX(-50%);
            background: rgba(0,0,0,0.6); padding: 15px; border-radius: 20px;
            display: flex; flex-direction: column; gap: 10px; align-items: center;
            color: #00ff88; backdrop-filter: blur(5px); z-index: 999;
        }
        .row { display: flex; gap: 10px; align-items: center; }
        input[type="text"] { width: 100px; padding: 5px; border-radius: 5px; border: none; text-align: center; }
        button { padding: 8px 20px; border-radius: 20px; border: none; font-weight: bold; cursor: pointer; }
        .btn-go { background: #00ff88; color: #000; }
        .btn-stop { background: #ff4757; color: #fff; }
        label { font-size: 12px; color: white; display: flex; align-items: center; gap: 5px; }
    </style>
</head>
<body>

<div id="videoContainer">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="hud">
    <div class="row">
        <input type="text" id="ip" placeholder="NodeMCU IP" value="192.168.0.105">
        <input type="text" id="peerId" placeholder="Laptop ID (Optional)">
    </div>
    <div class="row">
        <button class="btn-go" onclick="startTracking()">START</button>
        <button class="btn-stop" onclick="stopTracking()">STOP</button>
        <button style="background:#ffa502" onclick="resetMotor()">CENTER</button>
    </div>
    <div class="row">
        <label><input type="checkbox" id="invertDir" checked> Invert Direction</label>
        <div id="status">Ready</div>
    </div>
</div>

<script>
    let model, video, canvas, ctx;
    let isTracking = false;
    let peer = null;
    let motorPosition = 0; // Virtual position of motor (-100 to 100)
    let lastRequestTime = 0;

    // Initialize Video
    async function setupCamera() {
        video = document.getElementById('video');
        canvas = document.getElementById('canvas');
        ctx = canvas.getContext('2d');

        const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } },
            audio: false
        });
        video.srcObject = stream;
        
        return new Promise(resolve => {
            video.onloadedmetadata = () => {
                resize();
                resolve();
            };
        });
    }

    // Handle Resize/Rotate
    function resize() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
    }
    window.addEventListener('resize', resize);

    async function startTracking() {
        const ip = document.getElementById('ip').value;
        const pId = document.getElementById('peerId').value;
        if(!ip) return alert("Enter IP");

        document.getElementById('status').innerText = "Loading AI...";
        await setupCamera();
        model = await blazeface.load();
        
        // Start PeerJS Stream if ID provided
        if(pId) {
            peer = new Peer();
            peer.on('open', () => {
                peer.call(pId, video.srcObject);
                document.getElementById('status').innerText = "Streaming Active";
            });
        }

        isTracking = true;
        document.getElementById('status').innerText = "Tracking...";
        detectLoop();
    }

    function stopTracking() {
        isTracking = false;
        if(peer) peer.destroy();
        document.getElementById('status').innerText = "Stopped";
    }

    function resetMotor() {
        const ip = document.getElementById('ip').value;
        fetch(`http://${ip}/reset`).catch(e=>{});
        motorPosition = 0;
    }

    async function detectLoop() {
        if(!isTracking) return;

        const predictions = await model.estimateFaces(video, false);
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        if (predictions.length > 0) {
            const face = predictions[0];
            const start = face.topLeft;
            const end = face.bottomRight;
            
            // Draw Box
            ctx.strokeStyle = "#00ff88";
            ctx.lineWidth = 4;
            ctx.strokeRect(start[0], start[1], end[0] - start[0], end[1] - start[1]);

            // --- SMART TRACKING LOGIC ---
            
            // 1. Calculate Center dynamically (works for any orientation)
            const screenCenter = canvas.width / 2;
            const faceCenter = (start[0] + end[0]) / 2;
            
            // 2. Calculate Deviation (Error)
            const error = faceCenter - screenCenter;
            
            // 3. Deadzone (Don't move if user is roughly centered)
            if (Math.abs(error) > 30) {
                
                // 4. Proportional Movement Calculation
                // If error is small (walking), move 1 step.
                // If error is large (running), move 5 steps.
                let stepSize = Math.floor(Math.abs(error) / 40); 
                if (stepSize > 5) stepSize = 5; // Max jump limit
                if (stepSize < 1) stepSize = 1;

                // 5. Determine Direction
                const invert = document.getElementById('invertDir').checked;
                let direction = (error > 0) ? 1 : -1; 
                
                // NOTE: blazeface coordinates are not mirrored, but CSS is.
                // Usually: Face > Center means face is on Right.
                // We need to move Right (+).
                if(invert) direction *= -1;

                // 6. Update Virtual Motor Position
                motorPosition += (direction * stepSize);

                // Clamp to limits (-100 to 100)
                if (motorPosition > 100) motorPosition = 100;
                if (motorPosition < -100) motorPosition = -100;

                // 7. Send Command (Throttled to prevent flooding WiFi)
                const now = Date.now();
                if (now - lastRequestTime > 50) { // Max 20 commands per second
                    const ip = document.getElementById('ip').value;
                    // Send absolute target to NodeMCU
                    fetch(`http://${ip}/update?target=${motorPosition}`, {mode: 'no-cors'}).catch(()=>{});
                    lastRequestTime = now;
                }
            }
        }

        requestAnimationFrame(detectLoop);
    }
</script>
</body>
</html>
